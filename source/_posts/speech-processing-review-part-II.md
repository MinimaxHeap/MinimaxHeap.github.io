---
title: Speech Processing 回顾(二)
date: 2018-11-21 21:50:15
tags:
- Speech Processing
- Machine Learning
---
# Speech Processing 回顾(二)

## 傅里叶变换(Fourier Transform)
傅里叶变换是一个公式或者说是一个方法.我们不用了解具体内容是什么.但是需要知道傅里叶变换的功能是提取音频中的频率.
比如说我们有一段音高为C3和E5的合成音频. 人们当然能听出来这是一段和弦,但是计算机只能看到一段复杂的曲线他们看不到这是和弦. 而傅里叶变换可以将这段音频分解成不同频率的曲线. 通过傅里叶变换后的曲线可以得到这段音频是由什么音高的声音合成的.

另外在傅里叶变换中是对负无穷到正无穷的积分,这点在计算机中无法实现,所以只能使用DFT(Discrete 离散傅里叶变换)求一个差不多的解(够用了). 代价就是只能取到0-X Hz这段频率的波形曲线.再高的就算不出来了. 而且DFT 最终画出的图像是中心对称的周期型函数.

除了DFT还有另外一种傅里叶变换的变体, 短时傅里叶分析.(Short-Time Fourier Analysis). 在人们日常说话的时候频率是不断变化的所以想完整分析一句话的频率是非常困难的.所以需要取一小段时间(上一篇文章中所说的帧)进行分析, 这一小段时间可以看成他的波形是不变的,可以得到清晰的频率曲线. 这一小段时间可以看成一个窗(window)

我们需要分析一小段一小段的时间.怎么得到呢? 可以通过乘以一个窗函数(window function)得到. 窗函数的功能就是取一小段时间.最简单的窗函数就是由0和1组成的函数,想要的时间的地方函数值为1 不要的地方函数值为0.

除了这种最简单的窗函数还有一些高级的窗函数比如Hamming window. 这个函数的形状类似高斯分布, 中间高两边低. 这么做的原因是为了保证中间的部分占据更主要的地位而两边的那些因为音频不一定是恒定的所以避免出现太大变化影响分析的问题就降低了他们的权值. 不过不用担心 这些被削减权重的两端在其他的帧中会占据主要地位所以总体上讲还是一样的.

一般能 window length 窗的持续时间(长度) 在20-30ms左右.而递进的长度(Frame advance)在10-20ms每一帧与相邻帧是有重合的避免信息丢失的问题.

## 频谱图 Spectrograms
之前说到的波形图以及傅里叶变换后的曲线都是一个二维图 横轴是时间/频率 纵轴是响度.

但是频谱图是一个三维图(用点的颜色(深浅)表示这个点的大小). 频谱图其实很简单. 横轴是时间,纵轴是频率, 颜色深浅表示这个频率的在这个时间的强度.

频谱图相对于二位的波形图或者是频率图可以显示更多地信息, 而且也有了更多地变化方式. 比如Narrow和Wide-band 两种. 其中Narrow 以及wide是主观上的概念(而且可能仅对语音处理有效). Short window (<10ms)也就是wide band 可以更好的对时间进行分析但是就不能很好的分析频率了. 反之,narrow band可以很好的分析频率但是对时间分析就无法分析的特别好. 不能二者兼得的原因是, sample rate就那么多,如果都用来分析频率了那么就没有帧分析时间了. 因为根据离散傅里叶变换公式越多的sample可以得到越多的频率范围,但是越多的sample必然导致frame的减少. 所以不可兼得.

## 主成分分析 PCA
<grey>这是一个非常重要的工具,很多领域都会用到</grey>

有的时候我们有很多很多的数据,但是有些数据并不重要,比如9000hz的时间-强度曲线 对我们研究说话一点都不重要怎么办? 我们可以用PCA来进行降维吧9000个频率变成20个主要的维度,这样我们只需要研究这20个维度就可以了. 这个变换的原理可以从线性代数角都去讲,9000个频率就相当于9000个维度,我们完全可以用另外的9000个维度来表示这原来的9000个维度中的点.(变换坐标系嘛) 为什么我们要变换呢,是因为这样做可以把数据点中的分布用另外一种方式来表达出来.有些维度能够得到更分散的点 有些维度的点都挤在一堆. 更分散的维度就是主成分了. 根据线性代数的原理可知,只要是满秩的我们就必须还用同样数量的维度来表示.所以还是要用9000个维度来表示同样的信息量.不过前文也提到了有些维度的点都挤在一堆所以不同要,把这些剔除,只保留主成分也能取到很大的信息量(肯定会有信息损失但是损失30%不一定会有很大影响,也有可能过滤掉了很多噪音导致有更好的影响说不定) 虽然只保留了70%的信息量,但是维度如果能从9000降到50的话 还是方便的多的. 这就是PCA的作用.

### 维度的诅咒 curse of dimensionality
<grey>这是PCA能够解决的问题</grey>

设想一个正方形,如果我们想用一个更小的正方形来保证小正方形是大正方行的一半的话我们的边长需要是大正方形的0.707倍, 但是如果是一个立方体的话就需要是立方根倍了.大概0.8左右,如果是10维的话0.9都不够用,而高维的时候从面积的一半开始变化在增加一点点变化又会变得巨大,比如三维的时候0.8是0.512 但是0.9的时候就是0.7了,这会导致一个严重的问题,我们不能很好的感知这个边长和面积的关系(他不是线性的). 所以减少维度可以尽可能避免这个问题.