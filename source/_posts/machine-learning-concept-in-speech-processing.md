---
title: 语音处理领域中的一些机器学习概念
date: 2018-11-23 21:21:42
tags:
- Machine Learning
- Speech Processing
- GMM
---
# 语音处理领域中的一些机器学习概念
<grey>主要介绍GMM,Linear  Regression问题, Capacity, Cross Validation, Cross Entropy等问题</grey>
<!--more-->
## 什么是机器学习
- 小白版: 机器学习就是用一种设计者本人都不知道怎么实现的方式来解决一种特定问题的工具
- 初学者版: 机器学习是一种通过一系列的计算来不断优化自己的算法,当算法优秀到一定程度之后就可以投入到实际生活当中了.
- <grey>高级版暂时还不清楚 我也就是个初学者</grey>

## A Cardinal Rule 没有免费的午餐
按目前水平来说,没有一种算法能够极好地解决所有的问题. 越是针对特定问题的机器学习模型问题解决的就越好.

## Partitioning Data
大家都知道使用机器学习需要用到大量的数据集,数据集就是现有的信息.例如你想要机器学会加法 你需要给他一些例子让他见识到1+1=2 或者类似的加法等式才行,没见过的东西机器当然学不会啦. 那些例子就是数据集.那么怎么衡量机器学习的结果好还是不好呢, 我们就从同样的数据集中抽出一部分先不给机器看到,在机器训练好了之后让他做这些没见过的题然后看它考试水平怎么样. 给机器看到的部分也就是作业我们称之为训练集(training data),让机器做的考试题就是测试集test data. 一般的比例为7:3 9:1 99:1等等 取决于数据量.

## K-Fold与Cross Validation
有些时候我们抽取的训练集可能不能很好地反应整体的数据集,也就是测试集中的考试题在作业训练集里都没练过,最后结果会变得比较差怎么办? 有一个比较方便的办法就是我们通过K-Fold方法. 分别训练K次,每次都用其中一份作为测试集,其余作为训练集. 这个方法就跟切披萨一样,例如把一整块披萨切成5份,这样k=5,每次取一片披萨作为测试集,其余作为训练集.训练集比测试集就是4:1.重复让机器训练5次每次都用片的披萨作为测试集.这样就能得出一个稳定的机器学习训练的结果. 也可以只选用其中一个准确率比较高的模型作为最终模型.

交叉验证Cross Validation 就是使用K-Fold方法进行多次验证得出一个比较准确的结果,

## 高斯混合模型GMM Gaussians Mixture Model
[之前的文章](https://kevinvfeng.github.io/2018/11/20/speech-processing-review-part-I-md/)已经提到过高斯分布了,不过那个高斯分布是针对一个事物的.但是现实生活中的分布可能是比较复杂的他可以是有多个高斯分布混合而成.比如50个男生和50个女生或者50个大人以及50个小孩的身高分布. 男生与女生或者大人与小孩应该是分别满足高斯分布的而不是整体满足高斯分布.所以很多情况下我们可以用多个高斯分布去拟合这种情况.拟合的方法就是__MLE算法__也就是__最大似然估计__. 具体这个算法可以在他人的博客或者知乎中找到,这里就不详细介绍了.(我也不是完全会所以也讲不明白)

## MSE, Mean Square Error
<grey>一个用于回归问题的评价方法</grey>

对于分类问题大家都知道一个简单的衡量方法,就是看这个模型预测的准还是不准, 准的数量除以总数就是准确率.(相当于100道判断题,一道1分,最后看你总分是多少)

但是对于这种连续的题怎么知道机器学习的怎么样了呢? 通过MSE方法可以解决.MSE,通过计算每一次预测的情况以及真实情况的差值来判断,差的越多预测的就越不准,最终通过很多个题的平均值来得出结果. 同样用平方是为了解决平均时的正负号问题.

## 拟合,欠拟合,过拟合
<grey>拟合就是机器学习的过程,也叫泛化</grey>
这个知识点举个例子就会显得特别简单.

从前有个人叫小明,老师让他学习加法并给他一堆练习题和答案让他自学.(小明就是机器,练习题和答案就是训练集)

- 欠拟合: 小明开始学,学呀学,过了一段时间他会做十以内的加法了, 但是对于10以上的加法由于他手指头数量不够就不会做了, 这种时候老师给了他套卷子,里面有十以内的加法以及十以上的加法, 小明把十以内的加法都做对了,但是10以上的都填错了.这种情况,作业题错的多考试题错的多的情况也就是没有完全掌握的情况就是欠拟合

- 良好的拟合: 小明开始学,学呀学,过了一段时间他会做十以内以及十以上的加法了, 这种时候老师给了他套卷子,里面有十以内的加法以及十以上的加法, 小明把所有题都基本作对了.这种情况,作业题错的少考试题错的少的情况也就是基本掌握的情况就是良好的拟合 也是我们想要的拟合状态.

- 过拟合: 小明开始学,学呀学,过了一段时间他会做十以内以及十以上的加法了,然而他作了太多的题把所有见到的加法题的答案都背下来了,而加法是怎么算的却忘了(学傻了), 这种时候老师给了他套卷子,里面有十以内的加法以及十以上的加法, 小明把所有见过的原题都做对了 而没见过的题因为不会算加法了就部分做错了.这种情况,作业题错的少考试题错的多的情况就是过拟合 是训练过度的结果,遇到这种情况我们需要提早结束训练防止小明学傻了.

## Capacity
<grey>一个不会出现在正经机器学习课程中的东西</grey>

这东西其实挺没用的不想看可以不看,不过能解释部分问题.

在分类问题中(判断题或者选择题),其实是能找到数据点和答案对应的分界线的.比如与门(And gate)只有在x=y=1的情况加结果才是1.所以可以简单的画一条曲线(y = 1.5-x) 在这个函数之上的点是1 其他的时候结果都是0. 这个函数就是一条分界线. 当然很多时候分界线并不是直线.

那有些时候一条直线并不能成为一个成功的分界线啊.比如异或门(00,以及11的时候是0, 01,10的情况下是1),所以引入一个新的概念__VC dimension__ VC维越高能够分解的点就越多(反映在模型中就是参数越多),表现复杂问题的能力也就越好.
但是有时候模型能表现的很好跟实际表现的很好是两码事.所以Measureing capacity就是反应实际怎么样的.
但是这些术语没有什么实际意义.